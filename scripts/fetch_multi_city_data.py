"""
fetch_multi_city_data.py â€” å¤šåŸå¸‚å»ºç­‘ä¸POIæ•°æ®ç»Ÿä¸€è·å–è„šæœ¬ (v2)

ç­–ç•¥: æŒ‰è¡Œæ”¿åŒºåç§°ä½¿ç”¨ Overpass area æŸ¥è¯¢, ç²¾ç¡®åŒ¹é…è¡Œæ”¿åŒºè¾¹ç•Œ
ä¸å†ä½¿ç”¨çŸ©å½¢ BBox + ç“¦ç‰‡åˆ†å‰²

æ”¯æŒåŸå¸‚: æ·±åœ³(å·²æœ‰)ã€é‡åº†ã€åŒ—äº¬ã€ä¸Šæµ·ã€å¹¿å·ã€æˆéƒ½
æ•°æ®æº: Overpass API (OpenStreetMap)
è¾“å‡º: data/raw/{city}_buildings_raw.json, data/raw/{city}_poi_*.json
"""
import os
import sys
import json
import time
import logging
import argparse
import subprocess
from pathlib import Path

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[logging.StreamHandler()]
)
logger = logging.getLogger("MultiCityFetcher")

# ===========================================================================
#  åŸå¸‚é…ç½®: æŒ‰è¡Œæ”¿åŒºåç§°æŸ¥è¯¢, ä¸å†ä½¿ç”¨ BBox
# ===========================================================================
CITY_CONFIG = {
    "shenzhen": {
        "name": "æ·±åœ³å—å±±",
        "districts": ["å—å±±åŒº"],
        "admin_level": "8",
        "parent_area": "æ·±åœ³å¸‚",
        "desc": "å—å±±åŒº (å·²æœ‰æ•°æ®, é»˜è®¤è·³è¿‡)",
        # ä¿ç•™ bbox ä»…ç”¨äº POI æŸ¥è¯¢çš„åå¤‡
        "bbox": (22.48, 113.88, 22.58, 113.98),
    },
    "chongqing": {
        "name": "é‡åº†ä¸»åŸ",
        "districts": ["æ¸ä¸­åŒº", "å—å²¸åŒº", "æ±ŸåŒ—åŒº", "æ²™åªååŒº"],
        "admin_level": "8",
        "parent_area": "é‡åº†å¸‚",
        "desc": "æ¸ä¸­+å—å²¸+æ±ŸåŒ—+æ²™åªåæ ¸å¿ƒåŒº",
        "bbox": (29.45, 106.40, 29.68, 106.68),
    },
    "beijing": {
        "name": "åŒ—äº¬æ ¸å¿ƒ",
        "districts": ["æœé˜³åŒº", "æµ·æ·€åŒº", "è¥¿åŸåŒº", "ä¸œåŸåŒº"],
        "admin_level": "8",
        "parent_area": "åŒ—äº¬å¸‚",
        "desc": "æœé˜³+æµ·æ·€+è¥¿åŸ+ä¸œåŸæ ¸å¿ƒåŒº",
        "bbox": (39.87, 116.28, 39.98, 116.48),
    },
    "shanghai": {
        "name": "ä¸Šæµ·æ ¸å¿ƒ",
        "districts": ["æµ¦ä¸œæ–°åŒº", "é™å®‰åŒº", "é»„æµ¦åŒº"],
        "admin_level": "8",
        "parent_area": "ä¸Šæµ·å¸‚",
        "desc": "æµ¦ä¸œ+é™å®‰+é»„æµ¦",
        "bbox": (31.17, 121.42, 31.28, 121.53),
    },
    "guangzhou": {
        "name": "å¹¿å·æ ¸å¿ƒ",
        "districts": ["å¤©æ²³åŒº", "è¶Šç§€åŒº", "æµ·ç åŒº"],
        "admin_level": "8",
        "parent_area": "å¹¿å·å¸‚",
        "desc": "å¤©æ²³+è¶Šç§€+æµ·ç ",
        "bbox": (23.08, 113.22, 23.18, 113.33),
    },
    "chengdu": {
        "name": "æˆéƒ½æ ¸å¿ƒ",
        "districts": ["é”¦æ±ŸåŒº", "æ­¦ä¾¯åŒº", "é«˜æ–°åŒº"],
        "admin_level": "8",
        "parent_area": "æˆéƒ½å¸‚",
        "desc": "é”¦æ±Ÿ+æ­¦ä¾¯+é«˜æ–°åŒº",
        "bbox": (30.57, 103.98, 30.68, 104.12),
    },
}

OVERPASS_URL = "http://overpass-api.de/api/interpreter"


def ensure_deps():
    for lib in ["requests"]:
        try:
            __import__(lib)
        except ImportError:
            subprocess.check_call([sys.executable, "-m", "pip", "install", lib])


# ===========================================================================
#  Overpass è¯·æ±‚å·¥å…·
# ===========================================================================
def _overpass_request(query: str, retries: int = 4, timeout: int = 300):
    """å¸¦é‡è¯•çš„ Overpass API è¯·æ±‚, è¶…æ—¶æ—¶é—´æ›´é•¿ä»¥é€‚é…å¤§åŒºåŸŸæŸ¥è¯¢"""
    import requests
    for attempt in range(retries):
        try:
            logger.info(f"    ğŸ“¡ å‘é€ Overpass è¯·æ±‚ (ç¬¬{attempt+1}æ¬¡, è¶…æ—¶{timeout}s)...")
            resp = requests.post(OVERPASS_URL, data={'data': query}, timeout=timeout)
            if resp.status_code == 429:
                wait = 30 * (attempt + 1)
                logger.warning(f"    â³ Overpass é™æµ, ç­‰å¾… {wait}s åé‡è¯•...")
                time.sleep(wait)
                continue
            if resp.status_code == 504:
                wait = 20 * (attempt + 1)
                logger.warning(f"    â³ ç½‘å…³è¶…æ—¶ 504, ç­‰å¾… {wait}s åé‡è¯•...")
                time.sleep(wait)
                continue
            resp.raise_for_status()
            return resp.json()
        except requests.exceptions.Timeout:
            logger.warning(f"    â³ è¯·æ±‚è¶…æ—¶ (ç¬¬{attempt+1}æ¬¡), é‡è¯•...")
            time.sleep(15)
        except Exception as e:
            if attempt < retries - 1:
                logger.warning(f"    âš ï¸  è¯·æ±‚å¤±è´¥: {e}, é‡è¯•...")
                time.sleep(15)
            else:
                raise
    return None


# ===========================================================================
#  å»ºç­‘æ•°æ®è·å– â€” æŒ‰è¡Œæ”¿åŒºæŸ¥è¯¢
# ===========================================================================
def fetch_buildings(city_key: str, output_dir: Path) -> bool:
    """æŒ‰è¡Œæ”¿åŒºåç§°è·å–å»ºç­‘æ•°æ®, é€åŒºæŸ¥è¯¢ååˆå¹¶å»é‡"""
    config = CITY_CONFIG[city_key]
    output_file = output_dir / f"{city_key}_buildings_raw.json"

    logger.info(f"  ğŸ—ï¸  è·å– {config['name']} å»ºç­‘æ•°æ®...")
    logger.info(f"     ç›®æ ‡è¡Œæ”¿åŒº: {', '.join(config['districts'])}")

    all_elements = []
    seen_ids = set()
    failed_districts = []

    for idx, district in enumerate(config['districts']):
        logger.info(f"     ğŸ“¦ [{idx+1}/{len(config['districts'])}] æŸ¥è¯¢ {district}...")

        # ä½¿ç”¨ area æŸ¥è¯¢: é€šè¿‡è¡Œæ”¿åŒºåç§° + admin_level ç²¾ç¡®åŒ¹é…
        # å¯¹äºæŸäº›ç‰¹æ®ŠåŒºï¼ˆå¦‚"é«˜æ–°åŒº"ä¸æ˜¯æ ‡å‡†è¡Œæ”¿åŒºåˆ’ï¼‰ï¼Œä½¿ç”¨ bbox åå¤‡
        query = _build_district_query(district, config)

        try:
            data = _overpass_request(query, timeout=600)
            if data:
                new_count = 0
                for el in data.get('elements', []):
                    eid = el.get('id', 0)
                    if eid not in seen_ids:
                        seen_ids.add(eid)
                        all_elements.append(el)
                        new_count += 1
                total_in_response = len(data.get('elements', []))
                dup_count = total_in_response - new_count
                logger.info(f"        âœ… {district}: +{new_count} æ–°å…ƒç´ "
                            f" (é‡å¤è·³è¿‡: {dup_count}, ç´¯è®¡: {len(all_elements)})")
            else:
                logger.warning(f"        âš ï¸  {district}: è¯·æ±‚è¿”å›ç©º")
                failed_districts.append(district)
        except Exception as ex:
            logger.warning(f"        âš ï¸  {district} æŸ¥è¯¢å¤±è´¥: {ex}")
            failed_districts.append(district)

        # åŒºä¸åŒºä¹‹é—´ç­‰å¾…, é¿å… Overpass é™æµ
        if idx < len(config['districts']) - 1:
            wait = 12
            logger.info(f"        â³ ç­‰å¾… {wait}s åæŸ¥è¯¢ä¸‹ä¸€ä¸ªåŒº...")
            time.sleep(wait)

    if failed_districts:
        logger.warning(f"  âš ï¸  ä»¥ä¸‹åŒºåŸŸæŸ¥è¯¢å¤±è´¥: {', '.join(failed_districts)}")

    if not all_elements:
        logger.error(f"  âŒ å»ºç­‘æ•°æ®è·å–å¤±è´¥: æ‰€æœ‰åŒºåŸŸå‡æœªè¿”å›æ•°æ®")
        return False

    result = {"elements": all_elements}
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(result, f, ensure_ascii=False)

    size_mb = os.path.getsize(output_file) / (1024 * 1024)
    logger.info(f"  ğŸ“Š æ€»è®¡ {len(all_elements)} ä¸ªå»ºç­‘å…ƒç´  (å»é‡å)")
    logger.info(f"  âœ… å·²ä¿å­˜: {output_file.name} ({size_mb:.1f} MB)")
    return True


def _build_district_query(district: str, config: dict) -> str:
    """
    æ„å»º Overpass æŸ¥è¯¢è¯­å¥ã€‚
    ä¼˜å…ˆä½¿ç”¨ area æŸ¥è¯¢ (æŒ‰è¡Œæ”¿åŒºåç§°)ï¼Œå¯¹äºéæ ‡å‡†è¡Œæ”¿åŒºä½¿ç”¨ bbox åå¤‡ã€‚

    æ³¨æ„: ä¸æŒ‡å®š admin_levelï¼Œå› ä¸ºç›´è¾–å¸‚(é‡åº†/ä¸Šæµ·/åŒ—äº¬)çš„å¸‚è¾–åŒº
    admin_level=6ï¼Œè€Œæ™®é€šçœä¼šåŸå¸‚çš„åŒº admin_level=8ï¼Œæ— æ³•ç»Ÿä¸€ã€‚
    ä»…æŒ‰åç§°åŒ¹é… area å³å¯ï¼Œå› ä¸ºè¡Œæ”¿åŒºåç§°ï¼ˆå¦‚"æ¸ä¸­åŒº""é™å®‰åŒº"ï¼‰
    åœ¨å…¨å›½èŒƒå›´å†…åŸºæœ¬å”¯ä¸€ã€‚
    """
    # æŸäº›éæ ‡å‡†åŒºåˆ’ï¼ˆå¦‚ "é«˜æ–°åŒº"ï¼‰åœ¨ OSM ä¸­å¯èƒ½æ²¡æœ‰è¡Œæ”¿è¾¹ç•Œ
    # è¿™äº›æƒ…å†µä½¿ç”¨ bbox åå¤‡æŸ¥è¯¢
    non_standard_districts = ["é«˜æ–°åŒº", "é«˜æ–°æŠ€æœ¯äº§ä¸šå¼€å‘åŒº"]
    if district in non_standard_districts:
        logger.info(f"        â„¹ï¸  {district} éæ ‡å‡†è¡Œæ”¿åŒºåˆ’, ä½¿ç”¨ bbox åå¤‡æŸ¥è¯¢")
        bbox = config.get("bbox")
        if bbox:
            s, w, n, e = bbox
            return f"""
            [out:json][timeout:600][maxsize:1073741824];
            (
              way["building"]({s},{w},{n},{e});
              relation["building"]({s},{w},{n},{e});
            );
            out geom;
            """

    bbox = config.get("bbox")
    bbox_filter = f"({bbox[0]},{bbox[1]},{bbox[2]},{bbox[3]})" if bbox else ""

    # area æŸ¥è¯¢: å¢åŠ çˆ¶çº§åŒºåŸŸé™åˆ¶ï¼Œé˜²æ­¢å…¨å›½é‡ååŒºå†²çªï¼ˆå¦‚å®æ³¢é•¿æ˜¥ä¹±å…¥ï¼‰
    parent_area = config.get("parent_area", "")
    if parent_area:
        area_query = f'area["name"="{parent_area}"]->.city;\n    area["name"="{district}"](area.city)->.target;'
    else:
        area_query = f'area["name"="{district}"]["boundary"="administrative"]->.target;'

    query = f"""
    [out:json][timeout:600][maxsize:1073741824];
    {area_query}
    (
      way["building"](area.target){bbox_filter};
      relation["building"](area.target){bbox_filter};
    );
    out geom;
    """
    return query


# ===========================================================================
#  POI æ•°æ®è·å– â€” æŒ‰è¡Œæ”¿åŒº area æŸ¥è¯¢ï¼ˆä¸å»ºç­‘ä¸€è‡´ï¼‰
# ===========================================================================
def fetch_pois(city_key: str, output_dir: Path) -> bool:
    """æŒ‰è¡Œæ”¿åŒºè·å–æ•æ„Ÿç‚¹å’Œéœ€æ±‚ç‚¹ POI, èŒƒå›´ä¸å»ºç­‘ä¿æŒä¸€è‡´"""
    config = CITY_CONFIG[city_key]

    all_ok = True
    for poi_type in ["sensitive", "demand"]:
        output_file = output_dir / f"{city_key}_poi_{poi_type}_raw.json"

        if output_file.exists() and os.path.getsize(output_file) > 100:
            size_kb = os.path.getsize(output_file) / 1024
            logger.info(f"  âœ… {poi_type} POI å·²å­˜åœ¨: {output_file.name} ({size_kb:.0f} KB)")
            continue

        logger.info(f"  ğŸ“ è·å– {config['name']} {poi_type} POI (æŒ‰è¡Œæ”¿åŒº)...")

        all_elements = []
        seen_ids = set()

        for idx, district in enumerate(config['districts']):
            logger.info(f"     ğŸ“¦ POI [{idx+1}/{len(config['districts'])}] {district}...")

            query = _build_poi_query_for_district(district, config, poi_type)

            try:
                data = _overpass_request(query, timeout=300)
                if data:
                    for el in data.get('elements', []):
                        eid = el.get('id', 0)
                        if eid not in seen_ids:
                            seen_ids.add(eid)
                            all_elements.append(el)
                    logger.info(f"        âœ… +{len(data.get('elements', []))} (ç´¯è®¡å»é‡: {len(all_elements)})")
            except Exception as ex:
                logger.warning(f"        âš ï¸  {district} POI æŸ¥è¯¢å¤±è´¥: {ex}")

            if idx < len(config['districts']) - 1:
                time.sleep(8)

        if all_elements:
            result = {"elements": all_elements}
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(result, f, ensure_ascii=False)
            size_kb = os.path.getsize(output_file) / 1024
            logger.info(f"  ğŸ“Š {poi_type} POI: {len(all_elements)} ä¸ª (å»é‡å)")
            logger.info(f"  âœ… å·²ä¿å­˜: {output_file.name} ({size_kb:.0f} KB)")
        else:
            logger.error(f"  âŒ {poi_type} POI è·å–å¤±è´¥: æ‰€æœ‰åŒºåŸŸå‡æœªè¿”å›æ•°æ®")
            all_ok = False

        time.sleep(10)

    return all_ok


def _build_poi_query_for_district(district: str, config: dict, poi_type: str) -> str:
    """ä¸ºå•ä¸ªè¡Œæ”¿åŒºæ„å»º POI æŸ¥è¯¢"""
    # éæ ‡å‡†è¡Œæ”¿åŒºä½¿ç”¨ bbox åå¤‡
    non_standard_districts = ["é«˜æ–°åŒº", "é«˜æ–°æŠ€æœ¯äº§ä¸šå¼€å‘åŒº"]
    if district in non_standard_districts:
        bbox = config.get("bbox")
        if not bbox:
            return ""
        s, w, n, e = bbox
        area_filter = f"({s},{w},{n},{e})"
    else:
        bbox = config.get("bbox")
        bbox_filter = f"({bbox[0]},{bbox[1]},{bbox[2]},{bbox[3]})" if bbox else ""
        area_filter = f"(area.target){bbox_filter}"

    # æ„å»ºæŸ¥è¯¢å¤´
    if district in non_standard_districts:
        query_head = f'[out:json][timeout:300][maxsize:1073741824];'
    else:
        parent_area = config.get("parent_area", "")
        if parent_area:
            query_head = f"""[out:json][timeout:300][maxsize:1073741824];
    area["name"="{parent_area}"]->.city;
    area["name"="{district}"](area.city)->.target;"""
        else:
            query_head = f"""[out:json][timeout:300][maxsize:1073741824];
    area["name"="{district}"]["boundary"="administrative"]->.target;"""

    if poi_type == "sensitive":
        return f"""
        {query_head}
        (
          node["amenity"~"hospital|clinic|school|kindergarten|college|university|police"]{area_filter};
          way["amenity"~"hospital|clinic|school|kindergarten|college|university|police"]{area_filter};
        );
        out center;
        """
    else:
        return f"""
        {query_head}
        (
          node["building"~"commercial|office|residential|apartments"]{area_filter};
          way["building"~"commercial|office|residential|apartments"]{area_filter};
          node["amenity"~"restaurant|cafe|fast_food|marketplace"]{area_filter};
          node["shop"~"supermarket|convenience|mall"]{area_filter};
        );
        out center;
        """


# ===========================================================================
#  ä¸»å…¥å£
# ===========================================================================
if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="å¤šåŸå¸‚å»ºç­‘ä¸POIæ•°æ®ç»Ÿä¸€è·å– (v2: areaæŸ¥è¯¢)")
    parser.add_argument("--output", type=str, default="../data/raw",
                        help="åŸå§‹æ•°æ®è¾“å‡ºç›®å½•")
    parser.add_argument("--cities", type=str, default="all",
                        help="è¦è·å–çš„åŸå¸‚, é€—å·åˆ†éš”æˆ–'all'. "
                             "å¯é€‰: " + ", ".join(CITY_CONFIG.keys()))
    parser.add_argument("--buildings-only", action="store_true", default=False,
                        help="ä»…è·å–å»ºç­‘æ•°æ®, è·³è¿‡POI")
    parser.add_argument("--poi-only", action="store_true", default=False,
                        help="ä»…è·å–POIæ•°æ®, è·³è¿‡å»ºç­‘")
    args = parser.parse_args()

    output_path = Path(__file__).resolve().parent / args.output
    output_path.mkdir(parents=True, exist_ok=True)

    # è§£æåŸå¸‚åˆ—è¡¨
    if args.cities.lower() == "all":
        # é»˜è®¤è·³è¿‡å·²æœ‰æ•°æ®çš„æ·±åœ³
        cities = [k for k in CITY_CONFIG if k != "shenzhen"]
    else:
        cities = [c.strip() for c in args.cities.split(",")]

    logger.info("=" * 60)
    logger.info("ğŸ™ï¸  å¤šåŸå¸‚åœ°ç†æ•°æ®ç»Ÿä¸€è·å– (v2: è¡Œæ”¿åŒºç²¾ç¡®æŸ¥è¯¢)")
    logger.info(f"ğŸ“ è¾“å‡ºç›®å½•: {output_path}")
    logger.info(f"ğŸ¯ ç›®æ ‡åŸå¸‚: {', '.join(CITY_CONFIG[c]['name'] for c in cities if c in CITY_CONFIG)}")
    logger.info("=" * 60)

    ensure_deps()

    results = {}
    for i, city in enumerate(cities):
        if city not in CITY_CONFIG:
            logger.warning(f"æœªçŸ¥åŸå¸‚: {city}, è·³è¿‡")
            continue

        config = CITY_CONFIG[city]
        logger.info("")
        logger.info(f"â”â”â” [{i+1}/{len(cities)}] {config['name']} ({config['desc']}) â”â”â”")

        bld_ok = True
        poi_ok = True

        # è·å–å»ºç­‘
        if not args.poi_only:
            bld_ok = fetch_buildings(city, output_path)
            time.sleep(10)

        # è·å– POI
        if not args.buildings_only:
            poi_ok = fetch_pois(city, output_path)

        results[config['name']] = bld_ok and poi_ok

        # åŸå¸‚é—´é—´éš”, é¿å… Overpass é™æµ
        if i < len(cities) - 1:
            logger.info("  â³ ç­‰å¾… 15 ç§’åç»§ç»­ä¸‹ä¸€ä¸ªåŸå¸‚...")
            time.sleep(15)

    logger.info("")
    logger.info("=" * 60)
    logger.info("ğŸ“Š è·å–ç»“æœæ±‡æ€»:")
    for city_name, ok in results.items():
        status = "âœ… æˆåŠŸ" if ok else "âš ï¸  éƒ¨åˆ†å¤±è´¥"
        logger.info(f"  {city_name}: {status}")
    logger.info("=" * 60)
