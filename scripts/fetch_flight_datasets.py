"""
fetch_flight_datasets.py â€” é£è¡Œè½¨è¿¹æ•°æ®é›†ç»Ÿä¸€è·å–è„šæœ¬

è·å–ä»¥ä¸‹æ•°æ®é›†:
  1. UAV Delivery Dataset (GitHub, 6911æ¡æ¨¡æ‹Ÿé…é€è½¨è¿¹, 20+é£è¡Œå‚æ•°)
  2. AirLab CMU çœŸå®é£è¡Œèƒ½è€—æ•°æ® (DJI M100, 195æ¬¡é£è¡Œ)
  3. å›½å®¶åŸºç¡€å­¦ç§‘å…¬å…±ç§‘å­¦æ•°æ®ä¸­å¿ƒ æ— äººæœºé£è¡ŒçŠ¶æ€æ•°æ® (DJI M300)

è¾“å‡º: data/raw/uav_delivery/, data/raw/airlab_energy/, data/raw/nbsdc_flight/
"""
import os
import sys
import logging
import argparse
import subprocess
import zipfile
import json
import csv
import io
import glob
from pathlib import Path

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[logging.StreamHandler()]
)
logger = logging.getLogger("FlightDataFetcher")


def ensure_deps():
    """ç¡®ä¿ä¾èµ–å·²å®‰è£…"""
    for lib in ["requests", "tqdm"]:
        try:
            __import__(lib)
        except ImportError:
            logger.info(f"å®‰è£… {lib}...")
            subprocess.check_call([sys.executable, "-m", "pip", "install", lib])


# ===========================================================================
#  1. UAV Delivery Dataset
# ===========================================================================
def fetch_uav_delivery(output_dir: Path):
    """
    è·å– UAV Delivery Dataset â€” 6911æ¡æ¨¡æ‹Ÿé…é€è½¨è¿¹
    æ•°æ®æ¥æºä¼˜å…ˆçº§:
      1. GitHub ZIP ä¸‹è½½ (å¤šä¸ªä»“åº“é•œåƒ)
      2. Git clone
      3. HuggingFace datasets æœç´¢
    """
    import requests
    from tqdm import tqdm

    dest = output_dir / "uav_delivery"
    dest.mkdir(parents=True, exist_ok=True)

    marker = dest / "_download_complete"
    if marker.exists():
        logger.info(f"âœ… UAV Delivery Dataset å·²å­˜åœ¨, è·³è¿‡ä¸‹è½½ ({dest})")
        return True

    # æ–¹æ³•1: å°è¯•ä» GitHub ä¸‹è½½ zip å‹ç¼©åŒ…
    urls = [
        "https://github.com/saimouafaiz/UAV-Delievery/archive/refs/heads/main.zip",
        "https://github.com/OreateAI/UAV-Delivery/archive/refs/heads/main.zip",
        "https://github.com/YassineBenAbdelworked/UAV-Delievery/archive/refs/heads/main.zip",
        "https://github.com/elkinvg/UAV-Delievery/archive/refs/heads/main.zip",
        "https://github.com/qz701731tby/UAV-Delievery/archive/refs/heads/main.zip",
    ]

    zip_path = dest / "download.zip"
    downloaded = False

    for url in urls:
        logger.info(f"å°è¯•ä¸‹è½½: {url}")
        try:
            resp = requests.get(url, stream=True, timeout=30, 
                              allow_redirects=True)
            if resp.status_code == 200:
                total = int(resp.headers.get('content-length', 0))
                with open(zip_path, 'wb') as f:
                    with tqdm(total=total, unit='B', unit_scale=True,
                              desc="ğŸ“¥ UAV Delivery") as pbar:
                        for chunk in resp.iter_content(chunk_size=8192):
                            f.write(chunk)
                            pbar.update(len(chunk))
                downloaded = True
                break
            else:
                logger.warning(f"  HTTP {resp.status_code}")
        except Exception as e:
            logger.warning(f"  å¤±è´¥: {e}")

    # æ–¹æ³•2: Git clone
    if not downloaded:
        logger.info("ZIPä¸‹è½½å¤±è´¥, å°è¯• git clone...")
        clone_urls = [
            "https://github.com/saimouafaiz/UAV-Delievery.git",
            "https://github.com/OreateAI/UAV-Delivery.git",
            "https://github.com/elkinvg/UAV-Delievery.git",
        ]
        for clone_url in clone_urls:
            try:
                clone_dest = dest / "repo"
                if clone_dest.exists():
                    import shutil
                    shutil.rmtree(clone_dest)
                result = subprocess.run(
                    ["git", "clone", "--depth", "1", clone_url, str(clone_dest)],
                    capture_output=True, text=True, timeout=120
                )
                if result.returncode == 0:
                    downloaded = True
                    logger.info(f"âœ… Git clone æˆåŠŸ")
                    break
            except Exception as e:
                logger.warning(f"  clone å¤±è´¥: {e}")

    # æ–¹æ³•3: é€šè¿‡ HuggingFace datasets åº“æœç´¢åŒåæ•°æ®é›†
    if not downloaded:
        logger.info("GitHub ä¸å¯ç”¨, å°è¯• HuggingFace...")
        try:
            subprocess.check_call([sys.executable, "-m", "pip", "install", 
                                   "datasets", "-q"], timeout=60)
            from datasets import load_dataset
            # å°è¯•åŠ è½½å¯èƒ½å­˜åœ¨çš„ HuggingFace é•œåƒ
            hf_names = [
                "saimouafaiz/UAV-Delivery",
                "riotu-lab/UAV-Delivery-Dataset",
            ]
            for hf_name in hf_names:
                try:
                    ds = load_dataset(hf_name, split='train')
                    df = ds.to_pandas()
                    csv_path = dest / "uav_delivery_data.csv"
                    df.to_csv(csv_path, index=False)
                    downloaded = True
                    logger.info(f"âœ… HuggingFace ä¸‹è½½æˆåŠŸ: {len(df)} æ¡è®°å½•")
                    break
                except Exception:
                    continue
        except Exception as e:
            logger.warning(f"  HuggingFace ä¹Ÿå¤±è´¥: {e}")

    if not downloaded:
        logger.error("âŒ UAV Delivery Dataset æ‰€æœ‰ä¸‹è½½æ–¹å¼å‡å¤±è´¥")
        logger.info("ğŸ“‹ è¯·æ‰‹åŠ¨æœç´¢ä¸‹è½½: https://github.com/search?q=UAV-Delievery+dataset")
        logger.info("   æˆ–ä»è®ºæ–‡ 'Delivery with UAVs: a simulated dataset via ATS' è·å–")
        return False

    # è§£å‹ ZIP
    if zip_path.exists():
        logger.info("æ­£åœ¨è§£å‹...")
        try:
            with zipfile.ZipFile(zip_path, 'r') as zf:
                zf.extractall(dest)
            os.remove(zip_path)
        except Exception as e:
            logger.error(f"è§£å‹å¤±è´¥: {e}")
            return False

    marker.write_text("done")
    log_files = list(dest.rglob("*.log")) + list(dest.rglob("*.csv"))
    logger.info(f"ğŸ“Š UAV Delivery Dataset: å…±æ‰¾åˆ° {len(log_files)} ä¸ªæ•°æ®æ–‡ä»¶")
    return True


# ===========================================================================
#  2. AirLab CMU çœŸå®é£è¡Œèƒ½è€—æ•°æ®
# ===========================================================================
def fetch_airlab_energy(output_dir: Path):
    """
    è·å– AirLab CMU æ— äººæœºåŒ…è£¹é…é€é£è¡Œèƒ½è€—æ•°æ®é›†
    DJI Matrice 100, 209æ¬¡é£è¡Œ, å«ä½ç½®å’Œèƒ½è€—æ•°æ®
    æ•°æ®æ¥æº: Figshare (doi:10.1184/R1/12683453)
    """
    import requests
    from tqdm import tqdm

    dest = output_dir / "airlab_energy"
    dest.mkdir(parents=True, exist_ok=True)

    marker = dest / "_download_complete"
    if marker.exists():
        logger.info(f"âœ… AirLab èƒ½è€—æ•°æ®å·²å­˜åœ¨, è·³è¿‡ä¸‹è½½ ({dest})")
        return True

    # ç›´æ¥ä½¿ç”¨ Figshare æ–‡ä»¶ä¸‹è½½é“¾æ¥ (ä¸ç»è¿‡ API)
    # è¿™äº›é“¾æ¥å¯ä»¥ä» https://figshare.com/articles/dataset/12683453 é¡µé¢è·å–
    logger.info("æ­£åœ¨å°è¯•ä» Figshare ä¸‹è½½ AirLab æ•°æ®é›†...")

    # å°è¯• Figshare API è·å–å®é™…æ–‡ä»¶URL
    api_url = "https://api.figshare.com/v2/articles/12683453"
    files_to_download = []

    try:
        resp = requests.get(api_url, timeout=30)
        if resp.status_code == 200:
            try:
                article = resp.json()
                files_to_download = [
                    (f["name"], f["download_url"], f.get("size", 0))
                    for f in article.get("files", [])
                ]
                logger.info(f"  ä» Figshare API è·å–åˆ° {len(files_to_download)} ä¸ªæ–‡ä»¶")
            except Exception:
                logger.warning("  Figshare API å“åº”è§£æå¤±è´¥")
    except Exception as e:
        logger.warning(f"  Figshare API ä¸å¯è¾¾: {e}")

    # å¦‚æœ API å¤±è´¥ï¼Œä½¿ç”¨æ‰‹åŠ¨å¤‡ç”¨é“¾æ¥
    if not files_to_download:
        logger.info("  ä½¿ç”¨å¤‡ç”¨ç›´æ¥ä¸‹è½½é“¾æ¥...")
        files_to_download = [
            ("flight_data.zip", 
             "https://ndownloader.figshare.com/files/23585474", 0),
        ]

    downloaded_count = 0
    for fname, furl, fsize in files_to_download:
        fpath = dest / fname
        if fpath.exists() and os.path.getsize(fpath) > 1000:
            logger.info(f"  è·³è¿‡å·²å­˜åœ¨: {fname}")
            downloaded_count += 1
            continue

        logger.info(f"  ä¸‹è½½: {fname}")
        try:
            dl_resp = requests.get(furl, stream=True, timeout=120, 
                                   allow_redirects=True)
            dl_resp.raise_for_status()
            actual_size = int(dl_resp.headers.get('content-length', fsize))

            with open(fpath, 'wb') as f:
                with tqdm(total=actual_size, unit='B', unit_scale=True,
                          desc=f"ğŸ“¥ {fname}") as pbar:
                    for chunk in dl_resp.iter_content(chunk_size=8192):
                        f.write(chunk)
                        pbar.update(len(chunk))

            file_size = os.path.getsize(fpath)
            logger.info(f"  âœ… å·²ä¸‹è½½: {fname} ({file_size/(1024*1024):.1f} MB)")
            downloaded_count += 1
        except Exception as e:
            logger.error(f"  âŒ ä¸‹è½½å¤±è´¥ {fname}: {e}")

    # è§£å‹ ZIP æ–‡ä»¶
    for zfile in dest.glob("*.zip"):
        if os.path.getsize(zfile) > 1000:  # ç¡®ä¿ä¸æ˜¯ç©ºæ–‡ä»¶
            logger.info(f"  è§£å‹: {zfile.name}")
            try:
                with zipfile.ZipFile(zfile, 'r') as zf:
                    zf.extractall(dest)
                logger.info("  âœ… è§£å‹å®Œæˆ")
            except Exception as e:
                logger.warning(f"  è§£å‹å¤±è´¥: {e}")

    if downloaded_count > 0:
        marker.write_text("done")
        logger.info("âœ… AirLab èƒ½è€—æ•°æ®ä¸‹è½½å®Œæˆ")
        return True
    else:
        logger.error("âŒ AirLab æ•°æ®å…¨éƒ¨ä¸‹è½½å¤±è´¥")
        logger.info("å¤‡ç”¨æ–¹æ¡ˆ: è¯·æ‰‹åŠ¨è®¿é—® https://figshare.com/articles/dataset/12683453")
        return False


# ===========================================================================
#  3. å›½å®¶åŸºç¡€å­¦ç§‘å…¬å…±ç§‘å­¦æ•°æ®ä¸­å¿ƒ æ— äººæœºé£è¡ŒçŠ¶æ€æ•°æ®
# ===========================================================================
def fetch_nbsdc_flight(output_dir: Path):
    """
    è·å–å›½å®¶åŸºç¡€å­¦ç§‘å…¬å…±ç§‘å­¦æ•°æ®ä¸­å¿ƒçš„æ— äººæœºé£è¡ŒçŠ¶æ€æ•°æ®
    DJI M300, å«ä½ç½®/å§¿æ€/é€Ÿåº¦/IMU/RTK æ•°æ®, ~150MB
    æ•°æ®æ¥æº: nbsdc.cn
    æ³¨æ„: è¯¥æ•°æ®é›†å¯èƒ½éœ€è¦æ³¨å†Œç™»å½•åä¸‹è½½, æ­¤å¤„å°è¯•ç›´æ¥è·å–
    """
    import requests

    dest = output_dir / "nbsdc_flight"
    dest.mkdir(parents=True, exist_ok=True)

    marker = dest / "_download_complete"
    if marker.exists():
        logger.info(f"âœ… å›½å®¶æ•°æ®ä¸­å¿ƒé£è¡Œæ•°æ®å·²å­˜åœ¨, è·³è¿‡ ({dest})")
        return True

    # è¯¥æ•°æ®é›†é€šå¸¸åœ¨ nbsdc.cn å¹³å°ä¸Šï¼Œå¯èƒ½éœ€è¦æ‰‹åŠ¨ä¸‹è½½
    # æˆ‘ä»¬å°è¯•å‡ ä¸ªå¯èƒ½çš„ç›´æ¥ä¸‹è½½é“¾æ¥
    logger.info("æ­£åœ¨å°è¯•è·å–å›½å®¶æ•°æ®ä¸­å¿ƒæ— äººæœºé£è¡ŒçŠ¶æ€æ•°æ®...")

    # å°è¯•æœç´¢å·²çŸ¥çš„å…¬å¼€é•œåƒæˆ–ç›´æ¥é“¾æ¥
    possible_urls = [
        "https://www.nbsdc.cn/dataSet/handle/1",  # ç¤ºä¾‹
    ]

    # ç”±äºè¯¥æ•°æ®é›†é€šå¸¸éœ€è¦ç™»å½•ä¸‹è½½ï¼Œæˆ‘ä»¬åˆ›å»ºä¸€ä¸ªè¯´æ˜æ–‡ä»¶
    readme_path = dest / "README_ä¸‹è½½æŒ‡å—.md"
    readme_content = """# å›½å®¶åŸºç¡€å­¦ç§‘å…¬å…±ç§‘å­¦æ•°æ®ä¸­å¿ƒ - æ— äººæœºé£è¡ŒçŠ¶æ€æ•°æ®

## æ•°æ®ç®€ä»‹
- **æ•°æ®æº**: DJI M300 æ— äººæœºé£æ§æ•°æ®
- **é‡‡é›†æ–¹å¼**: ROS è®¢é˜…è¯é¢˜è·å–é£æ§æ•°æ®
- **å†…å®¹**: ä½ç½®ã€å§¿æ€ã€é£è¡Œé€Ÿåº¦ã€è§’é€Ÿåº¦ã€åŸå§‹IMUå’ŒRTKæ•°æ®
- **æ•°æ®é‡**: çº¦150MB

## ä¸‹è½½æ–¹å¼
1. è®¿é—® https://www.nbsdc.cn
2. æœç´¢ "æ— äººæœºé£è¡ŒçŠ¶æ€æ•°æ®"
3. æ³¨å†Œ/ç™»å½•åä¸‹è½½
4. å°†ä¸‹è½½çš„æ–‡ä»¶æ”¾åœ¨æ­¤ç›®å½•ä¸‹

## æ•°æ®æ ¼å¼
æ•°æ®é€šè¿‡ROS bagæ–‡ä»¶æˆ–CSVå¯¼å‡ºï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µ:
- timestamp: æ—¶é—´æˆ³
- position_x/y/z: ä½ç½®åæ ‡
- orientation_roll/pitch/yaw: å§¿æ€è§’
- velocity_x/y/z: é£è¡Œé€Ÿåº¦
- angular_velocity_x/y/z: è§’é€Ÿåº¦
- imu_accel_x/y/z: IMUåŠ é€Ÿåº¦
- imu_gyro_x/y/z: IMUé™€èºä»ª
- rtk_lat/lon/alt: RTKå·®åˆ†å®šä½
"""
    readme_path.write_text(readme_content, encoding='utf-8')
    logger.info(f"ğŸ“ å·²ç”Ÿæˆä¸‹è½½æŒ‡å—: {readme_path}")
    logger.warning("âš ï¸  è¯¥æ•°æ®é›†å¯èƒ½éœ€è¦æ‰‹åŠ¨ç™»å½• nbsdc.cn ä¸‹è½½")
    logger.info("   ä¹Ÿå¯ä»¥è·³è¿‡æ­¤æ•°æ®é›†ï¼Œç°æœ‰æ•°æ®è¶³ä»¥æ”¯æ’‘é¡¹ç›®")

    # å°è¯•ç›´æ¥ä¸‹è½½ï¼ˆå¯èƒ½ä¼šå¤±è´¥ï¼‰
    try:
        resp = requests.get(
            "https://www.nbsdc.cn/api/data/download",
            params={"keyword": "æ— äººæœºé£è¡ŒçŠ¶æ€"},
            timeout=15
        )
        if resp.status_code == 200 and len(resp.content) > 1000:
            data_path = dest / "flight_data.zip"
            data_path.write_bytes(resp.content)
            logger.info(f"âœ… æˆåŠŸä¸‹è½½: {data_path}")
            marker.write_text("done")
            return True
    except Exception:
        pass

    logger.info("â„¹ï¸  å·²åˆ›å»ºä¸‹è½½æŒ‡å—ï¼Œè¯·æ‰‹åŠ¨ä¸‹è½½åæ”¾å…¥ç›®å½•")
    return False


# ===========================================================================
#  ä¸»å…¥å£
# ===========================================================================
if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="é£è¡Œè½¨è¿¹æ•°æ®é›†ç»Ÿä¸€è·å–")
    parser.add_argument("--output", type=str, default="../data/raw",
                        help="åŸå§‹æ•°æ®è¾“å‡ºç›®å½•")
    parser.add_argument("--skip-uav-delivery", action="store_true",
                        help="è·³è¿‡ UAV Delivery Dataset")
    parser.add_argument("--skip-airlab", action="store_true",
                        help="è·³è¿‡ AirLab èƒ½è€—æ•°æ®")
    parser.add_argument("--skip-nbsdc", action="store_true",
                        help="è·³è¿‡å›½å®¶æ•°æ®ä¸­å¿ƒé£è¡Œæ•°æ®")
    args = parser.parse_args()

    output_path = Path(__file__).resolve().parent / args.output
    output_path.mkdir(parents=True, exist_ok=True)

    logger.info("=" * 60)
    logger.info("ğŸš é£è¡Œè½¨è¿¹æ•°æ®é›†ç»Ÿä¸€è·å–")
    logger.info(f"ğŸ“ è¾“å‡ºç›®å½•: {output_path}")
    logger.info("=" * 60)

    ensure_deps()

    results = {}

    if not args.skip_uav_delivery:
        results["UAV Delivery"] = fetch_uav_delivery(output_path)

    if not args.skip_airlab:
        results["AirLab Energy"] = fetch_airlab_energy(output_path)

    if not args.skip_nbsdc:
        results["NBSDC Flight"] = fetch_nbsdc_flight(output_path)

    logger.info("")
    logger.info("=" * 60)
    logger.info("ğŸ“Š ä¸‹è½½ç»“æœæ±‡æ€»:")
    for name, ok in results.items():
        status = "âœ… æˆåŠŸ" if ok else "âš ï¸  éœ€æ‰‹åŠ¨å¤„ç†"
        logger.info(f"  {name}: {status}")
    logger.info("=" * 60)
